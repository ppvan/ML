## Tiến độ học Machine Learning

- [x] Linear Regression
  - [x] Cost Function
  - [x] Gradient Descent
  - [x] Feature Scaling
  - [x] Vectorization (SIMD)
  - [x] Logistic Regression
  - [x] Overfitting, Underfitting
  - [x] Regularization

- [x] Neural Network
  - [x] Neural Network Forward Propagation
  - [ ] Numpy library
  - [ ] Tensor Flow, PyTorch or Pure Python?
  - [ ] Linear Algebra(vector and matrix)
  - [x] Activation Function alternative to Sigmoid
  - [x] Multi-class Classification
  - [x] Soft Max
  - [x] Adam (introduce)
  - [x] Other Layer types (Convolutional)
- [ ] What 's a good model?
  - [x] Test set, Dev set
  - [x] Model selection
  - [ ] Probility and statistics
  - [x] Baseline, Bias, Variance review
  - [x] Learning curve
- [x] What to try when model is not good?
  - [x] More training data (Fix high variance)
  - [x] Try smaller set of features (Fix high variance)
  - [x] Get additional features (Fix high bias)
  - [x] Add polynomial features (Fix high bias)
  - [x] Decrease regularization parameter (Fix high bias)
  - [x] Increase regularization parameter (Fix high variance)
  - [x] Neural network often low bias, so just add more data
- [x] How to collect more data?
  - [x] Augmentation (transform x -> x' but still same y)
  - [x] Tranfer learning
- [x] ML development process
- [x] Unethical side of ML
- [x] Skewed dataset, precision, recall, F1 score
- [x] Desision tree
  - [x] When to stop spliting?
  - [x] Impurity, Entropy
  - [x] Information gain
  - [x] One hot encoding (split feature)
  - [x] Continuous feature
  - [x] Regression decision tree (use variance)
  - [x] Tree ensemble
  - [x] Sample replacement, random forest, XGBoost
- [x] Unsupervised learning
  - [x] K-means, Elbow method
  - [x] Anomaly detection
    - [x] Normal distribution
    - [x] Choosing epsilon
- [x] Recommended system
  - [x]  Collaborative filtering 
  - [x]  Content based filtering
- [x] Reinforcement learning (learnt in AI class this semester)
  - [x] Markov Decision Process
  - [x] Q-learning
  - [x] Bellman equation
  - [x] Continoues State Space
  - [x] Neural Network for Q-learning
  - [x] Mini batch, soft update

## Deep learning

  - [x] Computation graph
  - [x] Derivative chain rule (Đạo hàm của hàm hợp)
  - [x] Vectorization
  - [x] Broadcasting in numpy
  - [x] Regularization
  - [x] Drop out regularization
  - [x] Normalization (từ xác suất thống kê)
  - [x] Vanishing/ Exploding gradient (very deep network problem)
  - [x] Gradient checking
  - [ ] Mini batch
  - [ ] Exponentlly weighted average (trung bình động)
  - [ ] Bias correction
  - [ ] Gradient descent with momentum
  - [ ] RMSprop
  - [ ] 